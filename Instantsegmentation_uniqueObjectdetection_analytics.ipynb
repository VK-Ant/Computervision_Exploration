{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AHsYMeBYgQl",
        "outputId": "fe7229f3-e262-4735-f964-756af182d6e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_1TDE0yYps_",
        "outputId": "ce7ae24f-89de-403c-f203-52ea37972b03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.62-py3-none-any.whl (825 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.2/825.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.62 ultralytics-thop-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.plotting import colors\n",
        "\n",
        "track_history = defaultdict(lambda: [])\n",
        "\n",
        "model = YOLO(\"yolov8n-seg.pt\")  # segmentation model\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/yolo/race.mp4\")\n",
        "# Get original video properties\n",
        "original_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "out_w = w\n",
        "out_h = h\n",
        "bar_width = out_w // 4\n",
        "seg_width = out_w - bar_width\n",
        "desired_fps = 10\n",
        "out = cv2.VideoWriter(\"3instance-segmentation-object-tracking.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), desired_fps, (out_w, out_h))\n",
        "\n",
        "# Define the classes of interest\n",
        "classes_of_interest = {'horse': 17, 'person': 0, 'car': 2, 'van': 8, 'bus': 5, 'tree': 62}\n",
        "unique_colors = {}  # To store unique colors for each track_id\n",
        "\n",
        "while True:\n",
        "    ret, im0 = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "\n",
        "    # Prepare the segmentation output\n",
        "    im0_seg = im0.copy()  # Make a copy for segmented output\n",
        "    counts = Counter()\n",
        "\n",
        "    results = model.track(im0, persist=True)\n",
        "\n",
        "    if results[0].boxes.id is not None and results[0].masks is not None:\n",
        "        masks = results[0].masks.xy\n",
        "        class_ids = results[0].boxes.cls.int().cpu().tolist()\n",
        "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "\n",
        "        for mask, class_id, track_id in zip(masks, class_ids, track_ids):\n",
        "            if class_id in classes_of_interest.values():\n",
        "                # Get the class name\n",
        "                class_name = [name for name, id in classes_of_interest.items() if id == class_id][0]\n",
        "\n",
        "                # Increment the count for the detected class\n",
        "                counts[class_name] += 1\n",
        "\n",
        "                # Assign a unique color for each track_id if not already assigned\n",
        "                if track_id not in unique_colors:\n",
        "                    unique_colors[track_id] = colors(int(track_id), True)\n",
        "\n",
        "                # Get the color for the specific object\n",
        "                color = unique_colors[track_id]\n",
        "\n",
        "                # Convert mask to a binary image\n",
        "                mask_image = np.zeros((h, w), dtype=np.uint8)\n",
        "                mask_image = cv2.drawContours(mask_image, [mask.astype(np.int32)], -1, 255, thickness=cv2.FILLED)\n",
        "\n",
        "                # Create a colored mask\n",
        "                colored_mask = np.zeros_like(im0)\n",
        "                colored_mask[mask_image == 255] = color\n",
        "\n",
        "                # Blend the colored mask with the original image\n",
        "                im0_seg = cv2.addWeighted(im0_seg, 1.0, colored_mask, 0.5, 0)\n",
        "\n",
        "    # Create a bar graph for displaying counts\n",
        "    counts_img = np.zeros((h, bar_width, 3), dtype=np.uint8)\n",
        "    max_count = max(counts.values(), default=1)  # Avoid division by zero\n",
        "    y_offset = 30\n",
        "\n",
        "    for i, (class_name, count) in enumerate(counts.items()):\n",
        "        bar_height = int((count / max_count) * (h - 60))  # Normalize bar height\n",
        "        cv2.rectangle(counts_img, (10, h - 30 - bar_height), (bar_width - 10, h - 30), colors(i, True), thickness=cv2.FILLED)\n",
        "        cv2.putText(counts_img, f\"{class_name}: {count}\", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "        y_offset += 40\n",
        "\n",
        "    # Resize segmented video to fit 3/4 of the width\n",
        "    im0_seg_resized = cv2.resize(im0_seg, (seg_width, h))\n",
        "\n",
        "    # Combine counts image with the resized segmented video\n",
        "    combined_img = np.hstack((counts_img, im0_seg_resized))\n",
        "\n",
        "    out.write(combined_img)\n",
        "    # cv2.imshow(\"instance-segmentation-object-tracking\", combined_img)\n",
        "    if cv2.waitKey(int(1000 / desired_fps)) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "out.release()\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BZAQQ9imPRZm",
        "outputId": "ccf8d53a-a88d-4dd3-b086-bd0b49b54af4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 2 horses, 220.8ms\n",
            "Speed: 3.7ms preprocess, 220.8ms inference, 53.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 horses, 180.9ms\n",
            "Speed: 2.5ms preprocess, 180.9ms inference, 43.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 horses, 185.3ms\n",
            "Speed: 3.8ms preprocess, 185.3ms inference, 41.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 horses, 181.4ms\n",
            "Speed: 2.5ms preprocess, 181.4ms inference, 44.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 horses, 184.5ms\n",
            "Speed: 2.5ms preprocess, 184.5ms inference, 40.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 horses, 205.3ms\n",
            "Speed: 3.4ms preprocess, 205.3ms inference, 39.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 horses, 176.3ms\n",
            "Speed: 2.5ms preprocess, 176.3ms inference, 42.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 horses, 182.2ms\n",
            "Speed: 3.4ms preprocess, 182.2ms inference, 33.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 184.5ms\n",
            "Speed: 3.3ms preprocess, 184.5ms inference, 31.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 182.7ms\n",
            "Speed: 3.1ms preprocess, 182.7ms inference, 33.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 172.7ms\n",
            "Speed: 2.7ms preprocess, 172.7ms inference, 34.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 186.0ms\n",
            "Speed: 2.6ms preprocess, 186.0ms inference, 39.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 187.0ms\n",
            "Speed: 2.6ms preprocess, 187.0ms inference, 40.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 176.6ms\n",
            "Speed: 3.6ms preprocess, 176.6ms inference, 37.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6 horses, 176.4ms\n",
            "Speed: 2.6ms preprocess, 176.4ms inference, 60.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 horses, 188.2ms\n",
            "Speed: 2.9ms preprocess, 188.2ms inference, 46.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 horses, 171.4ms\n",
            "Speed: 3.1ms preprocess, 171.4ms inference, 49.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 horses, 175.1ms\n",
            "Speed: 2.4ms preprocess, 175.1ms inference, 47.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6 horses, 190.0ms\n",
            "Speed: 2.5ms preprocess, 190.0ms inference, 44.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7 horses, 179.3ms\n",
            "Speed: 2.5ms preprocess, 179.3ms inference, 54.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6 horses, 277.6ms\n",
            "Speed: 3.3ms preprocess, 277.6ms inference, 65.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 277.6ms\n",
            "Speed: 4.8ms preprocess, 277.6ms inference, 81.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 282.8ms\n",
            "Speed: 2.6ms preprocess, 282.8ms inference, 78.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 272.0ms\n",
            "Speed: 3.1ms preprocess, 272.0ms inference, 62.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 horses, 271.7ms\n",
            "Speed: 2.5ms preprocess, 271.7ms inference, 48.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7 horses, 287.2ms\n",
            "Speed: 3.4ms preprocess, 287.2ms inference, 60.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 289.8ms\n",
            "Speed: 2.5ms preprocess, 289.8ms inference, 52.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 297.3ms\n",
            "Speed: 2.8ms preprocess, 297.3ms inference, 67.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 280.6ms\n",
            "Speed: 3.7ms preprocess, 280.6ms inference, 48.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 179.8ms\n",
            "Speed: 2.6ms preprocess, 179.8ms inference, 34.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 181.9ms\n",
            "Speed: 2.6ms preprocess, 181.9ms inference, 50.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 187.6ms\n",
            "Speed: 3.7ms preprocess, 187.6ms inference, 60.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 horses, 175.2ms\n",
            "Speed: 4.6ms preprocess, 175.2ms inference, 54.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 178.8ms\n",
            "Speed: 2.5ms preprocess, 178.8ms inference, 41.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 183.2ms\n",
            "Speed: 2.7ms preprocess, 183.2ms inference, 40.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 168.9ms\n",
            "Speed: 3.8ms preprocess, 168.9ms inference, 36.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 179.6ms\n",
            "Speed: 4.1ms preprocess, 179.6ms inference, 50.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 184.9ms\n",
            "Speed: 2.6ms preprocess, 184.9ms inference, 37.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 168.8ms\n",
            "Speed: 3.3ms preprocess, 168.8ms inference, 32.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 187.0ms\n",
            "Speed: 4.2ms preprocess, 187.0ms inference, 29.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 187.8ms\n",
            "Speed: 2.6ms preprocess, 187.8ms inference, 29.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 177.3ms\n",
            "Speed: 2.3ms preprocess, 177.3ms inference, 27.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 180.5ms\n",
            "Speed: 2.2ms preprocess, 180.5ms inference, 42.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 190.1ms\n",
            "Speed: 2.3ms preprocess, 190.1ms inference, 39.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 174.0ms\n",
            "Speed: 3.6ms preprocess, 174.0ms inference, 32.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 178.8ms\n",
            "Speed: 3.4ms preprocess, 178.8ms inference, 38.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 182.1ms\n",
            "Speed: 2.5ms preprocess, 182.1ms inference, 43.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 180.8ms\n",
            "Speed: 2.4ms preprocess, 180.8ms inference, 38.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 177.6ms\n",
            "Speed: 3.0ms preprocess, 177.6ms inference, 40.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 184.4ms\n",
            "Speed: 2.4ms preprocess, 184.4ms inference, 40.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 176.2ms\n",
            "Speed: 2.9ms preprocess, 176.2ms inference, 40.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 170.0ms\n",
            "Speed: 2.6ms preprocess, 170.0ms inference, 40.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 182.5ms\n",
            "Speed: 3.1ms preprocess, 182.5ms inference, 42.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 176.5ms\n",
            "Speed: 3.0ms preprocess, 176.5ms inference, 40.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 169.8ms\n",
            "Speed: 2.6ms preprocess, 169.8ms inference, 40.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 177.8ms\n",
            "Speed: 3.1ms preprocess, 177.8ms inference, 40.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 186.1ms\n",
            "Speed: 2.5ms preprocess, 186.1ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 181.4ms\n",
            "Speed: 2.4ms preprocess, 181.4ms inference, 38.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 178.3ms\n",
            "Speed: 2.5ms preprocess, 178.3ms inference, 36.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 horses, 2 cows, 186.6ms\n",
            "Speed: 3.3ms preprocess, 186.6ms inference, 39.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 268.0ms\n",
            "Speed: 2.5ms preprocess, 268.0ms inference, 73.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 281.9ms\n",
            "Speed: 2.6ms preprocess, 281.9ms inference, 71.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 263.8ms\n",
            "Speed: 3.0ms preprocess, 263.8ms inference, 71.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 272.5ms\n",
            "Speed: 2.5ms preprocess, 272.5ms inference, 82.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 264.1ms\n",
            "Speed: 2.8ms preprocess, 264.1ms inference, 72.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 280.9ms\n",
            "Speed: 2.6ms preprocess, 280.9ms inference, 79.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 281.6ms\n",
            "Speed: 2.6ms preprocess, 281.6ms inference, 79.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 278.7ms\n",
            "Speed: 2.6ms preprocess, 278.7ms inference, 84.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 283.4ms\n",
            "Speed: 4.6ms preprocess, 283.4ms inference, 51.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 225.7ms\n",
            "Speed: 2.6ms preprocess, 225.7ms inference, 35.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 183.0ms\n",
            "Speed: 2.2ms preprocess, 183.0ms inference, 35.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 173.1ms\n",
            "Speed: 2.6ms preprocess, 173.1ms inference, 45.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 175.9ms\n",
            "Speed: 2.9ms preprocess, 175.9ms inference, 47.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 184.3ms\n",
            "Speed: 2.3ms preprocess, 184.3ms inference, 41.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 193.4ms\n",
            "Speed: 3.5ms preprocess, 193.4ms inference, 33.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 177.6ms\n",
            "Speed: 3.1ms preprocess, 177.6ms inference, 46.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 172.8ms\n",
            "Speed: 2.5ms preprocess, 172.8ms inference, 45.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 214.1ms\n",
            "Speed: 2.4ms preprocess, 214.1ms inference, 35.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 180.7ms\n",
            "Speed: 2.6ms preprocess, 180.7ms inference, 41.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 172.1ms\n",
            "Speed: 2.4ms preprocess, 172.1ms inference, 42.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 181.1ms\n",
            "Speed: 2.7ms preprocess, 181.1ms inference, 56.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 181.7ms\n",
            "Speed: 3.0ms preprocess, 181.7ms inference, 41.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 175.4ms\n",
            "Speed: 2.4ms preprocess, 175.4ms inference, 40.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 182.4ms\n",
            "Speed: 5.9ms preprocess, 182.4ms inference, 27.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 176.9ms\n",
            "Speed: 2.6ms preprocess, 176.9ms inference, 33.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 222.1ms\n",
            "Speed: 2.8ms preprocess, 222.1ms inference, 35.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 192.2ms\n",
            "Speed: 4.7ms preprocess, 192.2ms inference, 36.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 188.1ms\n",
            "Speed: 2.6ms preprocess, 188.1ms inference, 37.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 175.8ms\n",
            "Speed: 2.2ms preprocess, 175.8ms inference, 36.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 189.2ms\n",
            "Speed: 2.3ms preprocess, 189.2ms inference, 30.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 185.4ms\n",
            "Speed: 3.4ms preprocess, 185.4ms inference, 52.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 172.0ms\n",
            "Speed: 2.6ms preprocess, 172.0ms inference, 44.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 181.6ms\n",
            "Speed: 3.8ms preprocess, 181.6ms inference, 49.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 175.1ms\n",
            "Speed: 3.3ms preprocess, 175.1ms inference, 41.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 171.1ms\n",
            "Speed: 3.6ms preprocess, 171.1ms inference, 39.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 186.8ms\n",
            "Speed: 3.2ms preprocess, 186.8ms inference, 33.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 177.3ms\n",
            "Speed: 2.6ms preprocess, 177.3ms inference, 21.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 185.2ms\n",
            "Speed: 2.9ms preprocess, 185.2ms inference, 34.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 175.3ms\n",
            "Speed: 3.3ms preprocess, 175.3ms inference, 39.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 186.3ms\n",
            "Speed: 3.0ms preprocess, 186.3ms inference, 33.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 178.1ms\n",
            "Speed: 2.7ms preprocess, 178.1ms inference, 31.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 181.4ms\n",
            "Speed: 2.6ms preprocess, 181.4ms inference, 46.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 290.2ms\n",
            "Speed: 2.5ms preprocess, 290.2ms inference, 57.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 265.3ms\n",
            "Speed: 2.4ms preprocess, 265.3ms inference, 55.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 3 horses, 260.8ms\n",
            "Speed: 4.7ms preprocess, 260.8ms inference, 72.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 272.1ms\n",
            "Speed: 2.6ms preprocess, 272.1ms inference, 60.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 295.4ms\n",
            "Speed: 2.5ms preprocess, 295.4ms inference, 55.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 258.9ms\n",
            "Speed: 2.4ms preprocess, 258.9ms inference, 61.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 280.8ms\n",
            "Speed: 2.5ms preprocess, 280.8ms inference, 59.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 270.9ms\n",
            "Speed: 2.4ms preprocess, 270.9ms inference, 60.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 314.3ms\n",
            "Speed: 2.6ms preprocess, 314.3ms inference, 41.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 269.3ms\n",
            "Speed: 3.2ms preprocess, 269.3ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 178.6ms\n",
            "Speed: 3.7ms preprocess, 178.6ms inference, 29.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 189.8ms\n",
            "Speed: 3.0ms preprocess, 189.8ms inference, 26.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 187.9ms\n",
            "Speed: 2.6ms preprocess, 187.9ms inference, 27.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 180.8ms\n",
            "Speed: 2.5ms preprocess, 180.8ms inference, 28.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 187.6ms\n",
            "Speed: 3.2ms preprocess, 187.6ms inference, 27.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 horses, 186.9ms\n",
            "Speed: 4.1ms preprocess, 186.9ms inference, 27.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 motorcycle, 3 horses, 174.6ms\n",
            "Speed: 3.4ms preprocess, 174.6ms inference, 30.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bird, 3 horses, 176.2ms\n",
            "Speed: 2.8ms preprocess, 176.2ms inference, 22.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bird, 3 horses, 186.4ms\n",
            "Speed: 3.1ms preprocess, 186.4ms inference, 19.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 horses, 180.1ms\n",
            "Speed: 2.4ms preprocess, 180.1ms inference, 22.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 horses, 178.7ms\n",
            "Speed: 3.5ms preprocess, 178.7ms inference, 23.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 horses, 184.4ms\n",
            "Speed: 2.5ms preprocess, 184.4ms inference, 22.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 horses, 189.7ms\n",
            "Speed: 2.5ms preprocess, 189.7ms inference, 21.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 horses, 176.3ms\n",
            "Speed: 2.5ms preprocess, 176.3ms inference, 28.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 horses, 178.3ms\n",
            "Speed: 2.6ms preprocess, 178.3ms inference, 23.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 194.3ms\n",
            "Speed: 2.5ms preprocess, 194.3ms inference, 26.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 177.5ms\n",
            "Speed: 2.6ms preprocess, 177.5ms inference, 34.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 172.1ms\n",
            "Speed: 2.4ms preprocess, 172.1ms inference, 29.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 184.5ms\n",
            "Speed: 2.5ms preprocess, 184.5ms inference, 39.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 187.9ms\n",
            "Speed: 2.6ms preprocess, 187.9ms inference, 24.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 175.4ms\n",
            "Speed: 3.3ms preprocess, 175.4ms inference, 25.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 175.9ms\n",
            "Speed: 2.2ms preprocess, 175.9ms inference, 21.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 horse, 189.8ms\n",
            "Speed: 2.3ms preprocess, 189.8ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 horse, 176.0ms\n",
            "Speed: 2.8ms preprocess, 176.0ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 horse, 177.7ms\n",
            "Speed: 2.4ms preprocess, 177.7ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 173.7ms\n",
            "Speed: 2.5ms preprocess, 173.7ms inference, 25.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 motorcycle, 3 horses, 187.7ms\n",
            "Speed: 2.6ms preprocess, 187.7ms inference, 28.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 horses, 176.0ms\n",
            "Speed: 2.9ms preprocess, 176.0ms inference, 27.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 horse, 174.7ms\n",
            "Speed: 2.6ms preprocess, 174.7ms inference, 19.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 horses, 187.2ms\n",
            "Speed: 2.4ms preprocess, 187.2ms inference, 32.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 horses, 178.6ms\n",
            "Speed: 5.5ms preprocess, 178.6ms inference, 21.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 175.2ms\n",
            "Speed: 2.6ms preprocess, 175.2ms inference, 21.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 173.5ms\n",
            "Speed: 2.5ms preprocess, 173.5ms inference, 19.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 horses, 210.8ms\n",
            "Speed: 3.7ms preprocess, 210.8ms inference, 24.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 237.4ms\n",
            "Speed: 3.8ms preprocess, 237.4ms inference, 49.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 horses, 267.3ms\n",
            "Speed: 2.5ms preprocess, 267.3ms inference, 42.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 horses, 268.5ms\n",
            "Speed: 2.4ms preprocess, 268.5ms inference, 41.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 horses, 268.4ms\n",
            "Speed: 2.5ms preprocess, 268.4ms inference, 35.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 279.9ms\n",
            "Speed: 3.5ms preprocess, 279.9ms inference, 32.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 dog, 2 horses, 270.7ms\n",
            "Speed: 3.0ms preprocess, 270.7ms inference, 59.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 horses, 269.8ms\n",
            "Speed: 2.5ms preprocess, 269.8ms inference, 63.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 horses, 277.4ms\n",
            "Speed: 2.6ms preprocess, 277.4ms inference, 53.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 horses, 298.3ms\n",
            "Speed: 2.6ms preprocess, 298.3ms inference, 51.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bird, 3 horses, 301.8ms\n",
            "Speed: 3.0ms preprocess, 301.8ms inference, 41.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 horses, 237.8ms\n",
            "Speed: 2.6ms preprocess, 237.8ms inference, 32.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bird, 3 horses, 187.4ms\n",
            "Speed: 2.7ms preprocess, 187.4ms inference, 19.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 182.5ms\n",
            "Speed: 2.9ms preprocess, 182.5ms inference, 32.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 motorcycle, 2 horses, 174.7ms\n",
            "Speed: 2.7ms preprocess, 174.7ms inference, 31.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 motorcycle, 2 horses, 194.1ms\n",
            "Speed: 2.5ms preprocess, 194.1ms inference, 31.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 horses, 177.4ms\n",
            "Speed: 2.8ms preprocess, 177.4ms inference, 35.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 horses, 176.8ms\n",
            "Speed: 2.5ms preprocess, 176.8ms inference, 34.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 181.1ms\n",
            "Speed: 2.5ms preprocess, 181.1ms inference, 30.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 178.0ms\n",
            "Speed: 3.8ms preprocess, 178.0ms inference, 23.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 189.9ms\n",
            "Speed: 4.0ms preprocess, 189.9ms inference, 48.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 172.5ms\n",
            "Speed: 3.2ms preprocess, 172.5ms inference, 46.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 190.3ms\n",
            "Speed: 2.6ms preprocess, 190.3ms inference, 37.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 horses, 216.6ms\n",
            "Speed: 2.5ms preprocess, 216.6ms inference, 40.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 horses, 181.6ms\n",
            "Speed: 2.6ms preprocess, 181.6ms inference, 46.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 horses, 189.7ms\n",
            "Speed: 2.5ms preprocess, 189.7ms inference, 52.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 horses, 179.9ms\n",
            "Speed: 2.4ms preprocess, 179.9ms inference, 76.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 horses, 179.6ms\n",
            "Speed: 2.5ms preprocess, 179.6ms inference, 66.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 horses, 187.1ms\n",
            "Speed: 4.5ms preprocess, 187.1ms inference, 47.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 horses, 182.2ms\n",
            "Speed: 2.5ms preprocess, 182.2ms inference, 47.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 horses, 194.3ms\n",
            "Speed: 2.6ms preprocess, 194.3ms inference, 54.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 horses, 226.9ms\n",
            "Speed: 4.7ms preprocess, 226.9ms inference, 56.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 horses, 185.0ms\n",
            "Speed: 4.0ms preprocess, 185.0ms inference, 47.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 horses, 190.9ms\n",
            "Speed: 2.2ms preprocess, 190.9ms inference, 51.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 horses, 188.5ms\n",
            "Speed: 3.0ms preprocess, 188.5ms inference, 73.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 horses, 186.3ms\n",
            "Speed: 3.2ms preprocess, 186.3ms inference, 60.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 horses, 190.4ms\n",
            "Speed: 2.6ms preprocess, 190.4ms inference, 46.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 horses, 178.9ms\n",
            "Speed: 2.8ms preprocess, 178.9ms inference, 78.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 horses, 181.5ms\n",
            "Speed: 3.7ms preprocess, 181.5ms inference, 72.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 horses, 189.7ms\n",
            "Speed: 2.5ms preprocess, 189.7ms inference, 71.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 horses, 173.2ms\n",
            "Speed: 2.5ms preprocess, 173.2ms inference, 61.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 horses, 183.1ms\n",
            "Speed: 2.5ms preprocess, 183.1ms inference, 101.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 horses, 179.4ms\n",
            "Speed: 2.5ms preprocess, 179.4ms inference, 64.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 horses, 262.3ms\n",
            "Speed: 2.3ms preprocess, 262.3ms inference, 87.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 horses, 268.4ms\n",
            "Speed: 2.8ms preprocess, 268.4ms inference, 84.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 263.9ms\n",
            "Speed: 2.5ms preprocess, 263.9ms inference, 97.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 272.6ms\n",
            "Speed: 4.9ms preprocess, 272.6ms inference, 109.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 269.2ms\n",
            "Speed: 2.6ms preprocess, 269.2ms inference, 122.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 269.5ms\n",
            "Speed: 2.5ms preprocess, 269.5ms inference, 102.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 280.5ms\n",
            "Speed: 2.6ms preprocess, 280.5ms inference, 100.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 288.4ms\n",
            "Speed: 5.4ms preprocess, 288.4ms inference, 91.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 310.3ms\n",
            "Speed: 3.6ms preprocess, 310.3ms inference, 90.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 173.9ms\n",
            "Speed: 2.9ms preprocess, 173.9ms inference, 72.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 175.3ms\n",
            "Speed: 2.9ms preprocess, 175.3ms inference, 44.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 192.0ms\n",
            "Speed: 2.6ms preprocess, 192.0ms inference, 48.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 175.6ms\n",
            "Speed: 2.7ms preprocess, 175.6ms inference, 48.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 170.6ms\n",
            "Speed: 2.7ms preprocess, 170.6ms inference, 63.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 202.0ms\n",
            "Speed: 2.5ms preprocess, 202.0ms inference, 60.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 176.9ms\n",
            "Speed: 2.7ms preprocess, 176.9ms inference, 48.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 181.9ms\n",
            "Speed: 5.6ms preprocess, 181.9ms inference, 52.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 197.2ms\n",
            "Speed: 2.8ms preprocess, 197.2ms inference, 79.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 181.0ms\n",
            "Speed: 2.5ms preprocess, 181.0ms inference, 65.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 175.3ms\n",
            "Speed: 3.8ms preprocess, 175.3ms inference, 63.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 200.6ms\n",
            "Speed: 2.5ms preprocess, 200.6ms inference, 67.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 173.4ms\n",
            "Speed: 2.5ms preprocess, 173.4ms inference, 93.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 175.4ms\n",
            "Speed: 2.5ms preprocess, 175.4ms inference, 65.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 4 horses, 302.3ms\n",
            "Speed: 2.5ms preprocess, 302.3ms inference, 339.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 3 horses, 177.2ms\n",
            "Speed: 2.6ms preprocess, 177.2ms inference, 72.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 horses, 186.6ms\n",
            "Speed: 2.9ms preprocess, 186.6ms inference, 37.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 horse, 172.2ms\n",
            "Speed: 2.4ms preprocess, 172.2ms inference, 40.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 horse, 176.1ms\n",
            "Speed: 2.6ms preprocess, 176.1ms inference, 31.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 horses, 208.6ms\n",
            "Speed: 2.6ms preprocess, 208.6ms inference, 33.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 horses, 176.3ms\n",
            "Speed: 2.6ms preprocess, 176.3ms inference, 38.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 horses, 172.4ms\n",
            "Speed: 4.6ms preprocess, 172.4ms inference, 32.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 horses, 182.8ms\n",
            "Speed: 2.6ms preprocess, 182.8ms inference, 39.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 horses, 187.8ms\n",
            "Speed: 2.6ms preprocess, 187.8ms inference, 34.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 horses, 180.3ms\n",
            "Speed: 2.5ms preprocess, 180.3ms inference, 37.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 horses, 176.6ms\n",
            "Speed: 2.6ms preprocess, 176.6ms inference, 31.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 191.1ms\n",
            "Speed: 2.5ms preprocess, 191.1ms inference, 35.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 172.1ms\n",
            "Speed: 2.5ms preprocess, 172.1ms inference, 36.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 170.4ms\n",
            "Speed: 2.6ms preprocess, 170.4ms inference, 44.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 189.9ms\n",
            "Speed: 3.2ms preprocess, 189.9ms inference, 53.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 277.9ms\n",
            "Speed: 3.1ms preprocess, 277.9ms inference, 83.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 278.7ms\n",
            "Speed: 3.2ms preprocess, 278.7ms inference, 69.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 270.4ms\n",
            "Speed: 2.4ms preprocess, 270.4ms inference, 79.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 284.0ms\n",
            "Speed: 2.6ms preprocess, 284.0ms inference, 53.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 horses, 280.7ms\n",
            "Speed: 2.5ms preprocess, 280.7ms inference, 58.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 269.4ms\n",
            "Speed: 2.6ms preprocess, 269.4ms inference, 62.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 288.1ms\n",
            "Speed: 2.5ms preprocess, 288.1ms inference, 62.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 294.8ms\n",
            "Speed: 4.0ms preprocess, 294.8ms inference, 48.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 286.6ms\n",
            "Speed: 2.5ms preprocess, 286.6ms inference, 55.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 4 horses, 192.3ms\n",
            "Speed: 2.5ms preprocess, 192.3ms inference, 35.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 4 horses, 176.8ms\n",
            "Speed: 2.5ms preprocess, 176.8ms inference, 37.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 4 horses, 191.7ms\n",
            "Speed: 2.5ms preprocess, 191.7ms inference, 40.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 4 horses, 172.9ms\n",
            "Speed: 2.8ms preprocess, 172.9ms inference, 41.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 176.9ms\n",
            "Speed: 2.6ms preprocess, 176.9ms inference, 39.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 180.5ms\n",
            "Speed: 2.9ms preprocess, 180.5ms inference, 58.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 170.6ms\n",
            "Speed: 2.5ms preprocess, 170.6ms inference, 42.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 174.8ms\n",
            "Speed: 4.9ms preprocess, 174.8ms inference, 33.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 188.1ms\n",
            "Speed: 2.9ms preprocess, 188.1ms inference, 47.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 174.5ms\n",
            "Speed: 2.6ms preprocess, 174.5ms inference, 32.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 187.7ms\n",
            "Speed: 2.7ms preprocess, 187.7ms inference, 33.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 179.0ms\n",
            "Speed: 3.5ms preprocess, 179.0ms inference, 33.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 173.1ms\n",
            "Speed: 3.2ms preprocess, 173.1ms inference, 37.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 195.6ms\n",
            "Speed: 3.6ms preprocess, 195.6ms inference, 36.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 205.0ms\n",
            "Speed: 2.9ms preprocess, 205.0ms inference, 36.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 5 horses, 177.0ms\n",
            "Speed: 2.4ms preprocess, 177.0ms inference, 27.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 193.9ms\n",
            "Speed: 3.0ms preprocess, 193.9ms inference, 43.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 180.2ms\n",
            "Speed: 2.7ms preprocess, 180.2ms inference, 28.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 189.9ms\n",
            "Speed: 2.5ms preprocess, 189.9ms inference, 31.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 198.3ms\n",
            "Speed: 2.9ms preprocess, 198.3ms inference, 48.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 175.5ms\n",
            "Speed: 2.9ms preprocess, 175.5ms inference, 40.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 203.4ms\n",
            "Speed: 4.0ms preprocess, 203.4ms inference, 25.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 230.8ms\n",
            "Speed: 2.9ms preprocess, 230.8ms inference, 33.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 179.5ms\n",
            "Speed: 2.5ms preprocess, 179.5ms inference, 40.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 187.3ms\n",
            "Speed: 3.2ms preprocess, 187.3ms inference, 45.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 182.3ms\n",
            "Speed: 3.0ms preprocess, 182.3ms inference, 43.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 174.7ms\n",
            "Speed: 2.6ms preprocess, 174.7ms inference, 45.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 180.6ms\n",
            "Speed: 2.6ms preprocess, 180.6ms inference, 50.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 183.4ms\n",
            "Speed: 2.6ms preprocess, 183.4ms inference, 40.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 175.2ms\n",
            "Speed: 2.6ms preprocess, 175.2ms inference, 37.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 176.4ms\n",
            "Speed: 2.8ms preprocess, 176.4ms inference, 39.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 286.9ms\n",
            "Speed: 2.5ms preprocess, 286.9ms inference, 64.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 271.6ms\n",
            "Speed: 3.3ms preprocess, 271.6ms inference, 68.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 275.0ms\n",
            "Speed: 3.5ms preprocess, 275.0ms inference, 58.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 4 horses, 266.6ms\n",
            "Speed: 2.7ms preprocess, 266.6ms inference, 83.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 282.6ms\n",
            "Speed: 3.1ms preprocess, 282.6ms inference, 81.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 272.3ms\n",
            "Speed: 3.4ms preprocess, 272.3ms inference, 43.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 298.8ms\n",
            "Speed: 2.5ms preprocess, 298.8ms inference, 58.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 298.9ms\n",
            "Speed: 2.5ms preprocess, 298.9ms inference, 54.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 288.5ms\n",
            "Speed: 2.6ms preprocess, 288.5ms inference, 58.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 176.3ms\n",
            "Speed: 2.6ms preprocess, 176.3ms inference, 45.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 172.0ms\n",
            "Speed: 2.5ms preprocess, 172.0ms inference, 36.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 191.8ms\n",
            "Speed: 2.9ms preprocess, 191.8ms inference, 39.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 175.0ms\n",
            "Speed: 2.8ms preprocess, 175.0ms inference, 29.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 178.6ms\n",
            "Speed: 2.6ms preprocess, 178.6ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 horses, 188.1ms\n",
            "Speed: 2.8ms preprocess, 188.1ms inference, 43.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 175.5ms\n",
            "Speed: 3.0ms preprocess, 175.5ms inference, 53.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 172.7ms\n",
            "Speed: 2.6ms preprocess, 172.7ms inference, 34.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 191.4ms\n",
            "Speed: 2.7ms preprocess, 191.4ms inference, 21.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 173.6ms\n",
            "Speed: 3.2ms preprocess, 173.6ms inference, 35.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 177.9ms\n",
            "Speed: 3.3ms preprocess, 177.9ms inference, 35.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 187.4ms\n",
            "Speed: 2.4ms preprocess, 187.4ms inference, 36.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 186.3ms\n",
            "Speed: 2.5ms preprocess, 186.3ms inference, 37.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 177.4ms\n",
            "Speed: 3.1ms preprocess, 177.4ms inference, 37.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 175.5ms\n",
            "Speed: 2.7ms preprocess, 175.5ms inference, 57.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 181.5ms\n",
            "Speed: 3.2ms preprocess, 181.5ms inference, 42.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 177.8ms\n",
            "Speed: 2.5ms preprocess, 177.8ms inference, 40.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 172.7ms\n",
            "Speed: 2.7ms preprocess, 172.7ms inference, 44.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 175.2ms\n",
            "Speed: 2.8ms preprocess, 175.2ms inference, 56.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 179.0ms\n",
            "Speed: 2.6ms preprocess, 179.0ms inference, 45.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 170.8ms\n",
            "Speed: 2.5ms preprocess, 170.8ms inference, 40.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 186.0ms\n",
            "Speed: 3.3ms preprocess, 186.0ms inference, 46.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 horses, 170.5ms\n",
            "Speed: 2.3ms preprocess, 170.5ms inference, 49.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 horses, 175.4ms\n",
            "Speed: 2.5ms preprocess, 175.4ms inference, 37.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 horses, 185.9ms\n",
            "Speed: 2.2ms preprocess, 185.9ms inference, 41.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 horses, 191.0ms\n",
            "Speed: 3.1ms preprocess, 191.0ms inference, 46.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 176.1ms\n",
            "Speed: 3.0ms preprocess, 176.1ms inference, 46.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 186.7ms\n",
            "Speed: 2.5ms preprocess, 186.7ms inference, 46.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 184.3ms\n",
            "Speed: 2.5ms preprocess, 184.3ms inference, 47.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 173.2ms\n",
            "Speed: 3.2ms preprocess, 173.2ms inference, 58.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 186.5ms\n",
            "Speed: 3.3ms preprocess, 186.5ms inference, 55.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 horses, 285.8ms\n",
            "Speed: 2.9ms preprocess, 285.8ms inference, 73.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 5 horses, 288.2ms\n",
            "Speed: 2.5ms preprocess, 288.2ms inference, 101.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 5 horses, 272.6ms\n",
            "Speed: 2.5ms preprocess, 272.6ms inference, 79.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 5 horses, 283.9ms\n",
            "Speed: 3.0ms preprocess, 283.9ms inference, 70.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 5 horses, 268.8ms\n",
            "Speed: 2.7ms preprocess, 268.8ms inference, 78.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 5 horses, 277.4ms\n",
            "Speed: 2.5ms preprocess, 277.4ms inference, 83.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 5 horses, 296.5ms\n",
            "Speed: 2.4ms preprocess, 296.5ms inference, 80.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 5 horses, 310.5ms\n",
            "Speed: 2.6ms preprocess, 310.5ms inference, 82.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 6 horses, 290.8ms\n",
            "Speed: 2.8ms preprocess, 290.8ms inference, 81.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 6 horses, 182.0ms\n",
            "Speed: 2.5ms preprocess, 182.0ms inference, 55.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 5 horses, 176.5ms\n",
            "Speed: 2.6ms preprocess, 176.5ms inference, 58.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 6 horses, 189.1ms\n",
            "Speed: 2.8ms preprocess, 189.1ms inference, 52.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 6 horses, 182.8ms\n",
            "Speed: 2.6ms preprocess, 182.8ms inference, 50.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 6 horses, 176.8ms\n",
            "Speed: 2.5ms preprocess, 176.8ms inference, 58.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 5 horses, 196.1ms\n",
            "Speed: 2.9ms preprocess, 196.1ms inference, 73.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 5 horses, 182.7ms\n",
            "Speed: 2.7ms preprocess, 182.7ms inference, 55.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 5 horses, 176.1ms\n",
            "Speed: 2.6ms preprocess, 176.1ms inference, 44.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 6 horses, 183.8ms\n",
            "Speed: 2.4ms preprocess, 183.8ms inference, 69.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 6 horses, 184.1ms\n",
            "Speed: 2.9ms preprocess, 184.1ms inference, 50.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 6 horses, 172.6ms\n",
            "Speed: 2.9ms preprocess, 172.6ms inference, 57.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 6 horses, 181.5ms\n",
            "Speed: 2.6ms preprocess, 181.5ms inference, 64.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 6 horses, 176.4ms\n",
            "Speed: 2.5ms preprocess, 176.4ms inference, 59.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 6 horses, 180.0ms\n",
            "Speed: 2.6ms preprocess, 180.0ms inference, 62.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 6 horses, 184.9ms\n",
            "Speed: 2.5ms preprocess, 184.9ms inference, 56.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 6 horses, 184.7ms\n",
            "Speed: 2.5ms preprocess, 184.7ms inference, 59.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 6 horses, 201.0ms\n",
            "Speed: 2.5ms preprocess, 201.0ms inference, 55.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 6 horses, 184.1ms\n",
            "Speed: 2.4ms preprocess, 184.1ms inference, 60.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 6 horses, 175.4ms\n",
            "Speed: 2.5ms preprocess, 175.4ms inference, 60.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 6 horses, 179.9ms\n",
            "Speed: 2.6ms preprocess, 179.9ms inference, 48.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 6 horses, 191.7ms\n",
            "Speed: 2.5ms preprocess, 191.7ms inference, 45.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 6 horses, 175.2ms\n",
            "Speed: 3.1ms preprocess, 175.2ms inference, 53.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 6 horses, 180.5ms\n",
            "Speed: 3.1ms preprocess, 180.5ms inference, 46.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 7 horses, 230.6ms\n",
            "Speed: 2.4ms preprocess, 230.6ms inference, 54.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 7 horses, 173.3ms\n",
            "Speed: 2.8ms preprocess, 173.3ms inference, 53.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 6 horses, 176.5ms\n",
            "Speed: 2.7ms preprocess, 176.5ms inference, 72.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 7 horses, 173.2ms\n",
            "Speed: 4.7ms preprocess, 173.2ms inference, 58.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 6 horses, 175.5ms\n",
            "Speed: 2.4ms preprocess, 175.5ms inference, 53.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 6 horses, 274.7ms\n",
            "Speed: 3.4ms preprocess, 274.7ms inference, 94.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 6 horses, 274.1ms\n",
            "Speed: 2.4ms preprocess, 274.1ms inference, 106.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 6 horses, 279.8ms\n",
            "Speed: 2.5ms preprocess, 279.8ms inference, 104.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 6 horses, 283.8ms\n",
            "Speed: 2.6ms preprocess, 283.8ms inference, 80.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 6 horses, 267.7ms\n",
            "Speed: 2.5ms preprocess, 267.7ms inference, 76.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 6 horses, 276.1ms\n",
            "Speed: 2.6ms preprocess, 276.1ms inference, 86.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 6 horses, 283.0ms\n",
            "Speed: 2.5ms preprocess, 283.0ms inference, 98.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 5 horses, 270.9ms\n",
            "Speed: 2.5ms preprocess, 270.9ms inference, 59.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 5 horses, 179.3ms\n",
            "Speed: 2.5ms preprocess, 179.3ms inference, 56.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 6 horses, 188.7ms\n",
            "Speed: 3.1ms preprocess, 188.7ms inference, 58.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 6 horses, 189.1ms\n",
            "Speed: 4.3ms preprocess, 189.1ms inference, 68.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 6 horses, 171.1ms\n",
            "Speed: 2.6ms preprocess, 171.1ms inference, 62.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 6 horses, 169.7ms\n",
            "Speed: 2.4ms preprocess, 169.7ms inference, 55.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 6 horses, 168.8ms\n",
            "Speed: 3.8ms preprocess, 168.8ms inference, 67.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 6 horses, 174.7ms\n",
            "Speed: 2.5ms preprocess, 174.7ms inference, 56.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 6 horses, 171.6ms\n",
            "Speed: 2.4ms preprocess, 171.6ms inference, 59.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 6 horses, 182.6ms\n",
            "Speed: 2.8ms preprocess, 182.6ms inference, 54.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 6 horses, 175.4ms\n",
            "Speed: 2.6ms preprocess, 175.4ms inference, 54.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 6 horses, 185.6ms\n",
            "Speed: 2.8ms preprocess, 185.6ms inference, 60.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 6 horses, 185.2ms\n",
            "Speed: 2.6ms preprocess, 185.2ms inference, 67.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 6 horses, 175.6ms\n",
            "Speed: 2.3ms preprocess, 175.6ms inference, 60.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 5 horses, 190.0ms\n",
            "Speed: 3.0ms preprocess, 190.0ms inference, 57.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-aaaeaf9d12ae>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrack\u001b[0;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# batch-size 1 for tracking in videos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"track\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     def val(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;31m# Postprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprofilers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim0s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_predict_postprocess_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/segment/predict.py\u001b[0m in \u001b[0;36mpostprocess\u001b[0;34m(self, preds, img, orig_imgs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_mask_native\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# HWC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# HWC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/ops.py\u001b[0m in \u001b[0;36mprocess_mask\u001b[0;34m(protos, masks_in, bboxes, shape, upsample)\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsampled_bboxes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# CHW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupsample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bilinear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# CHW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   4063\u001b[0m                 return importlib.import_module('torch._decomp.decompositions')._upsample_linear_vec(\n\u001b[1;32m   4064\u001b[0m                     input, output_size, align_corners, scale_factors)\n\u001b[0;32m-> 4065\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_bilinear2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4066\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"trilinear\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4067\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0malign_corners\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-kHtlReNBuq"
      },
      "source": [
        "# july 9 demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7TK6gmCxxcJ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.plotting import Annotator\n",
        "from ultralytics.solutions import speed_estimation\n",
        "\n",
        "# Initialize YOLO models\n",
        "object_detection_model = YOLO(\"yolov8s.pt\")\n",
        "speed_estimation_model = YOLO(\"yolov8n.pt\")\n",
        "names = speed_estimation_model.model.names\n",
        "\n",
        "# Open video file\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/yolo/h1.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "\n",
        "# Get video properties\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Initialize video writer\n",
        "out = cv2.VideoWriter(\"Distribution_speed_distance_visual_scatter_unique1hor_car.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), fps, (w + w // 3, h))\n",
        "\n",
        "frame_count = 0\n",
        "data = {}\n",
        "labels = []\n",
        "class_counts_over_time = {}\n",
        "speed_over_time = {}\n",
        "distance_over_time = {}\n",
        "\n",
        "# Center point and pixel per meter for distance calculation\n",
        "center_point = (0, h)\n",
        "pixel_per_meter = 10\n",
        "\n",
        "# Line points for speed estimation\n",
        "line_pts = [(0, 360), (1280, 360)]\n",
        "\n",
        "# Initialize speed-estimation object\n",
        "speed_obj = speed_estimation.SpeedEstimator(names=names, reg_pts=line_pts, view_img=False)\n",
        "\n",
        "# Colors for text and bounding box\n",
        "txt_color, txt_background, bbox_clr = ((0, 0, 0), (255, 255, 255), (255, 0, 255))\n",
        "\n",
        "def create_pie_chart(data):\n",
        "    fig, ax = plt.subplots(figsize=(4, 3))  # Aspect ratio of 4:3\n",
        "    ax.pie(data.values(), labels=data.keys(), autopct='%1.1f%%')\n",
        "    ax.legend()\n",
        "    ax.set_title(\"Total Percentage of Individual Class Perspective\")\n",
        "    plt.close(fig)\n",
        "    return fig\n",
        "\n",
        "def create_bar_plot(data):\n",
        "    fig, ax = plt.subplots(figsize=(4, 3))  # Aspect ratio of 4:3\n",
        "    colors = plt.cm.get_cmap('tab10', len(data))  # Use 'tab20' colormap\n",
        "    ax.bar(data.keys(), data.values(), color=[colors(i) for i in range(len(data))])\n",
        "    ax.legend()\n",
        "    ax.set_title(\"Distribution of Each Class\")\n",
        "    ax.set_xlabel(\"Class\")\n",
        "    ax.set_ylabel(\"Count\")\n",
        "    plt.close(fig)\n",
        "    return fig\n",
        "\n",
        "def create_multiple_line_plot(speed_data, distance_data, frame_count):\n",
        "    fig, ax = plt.subplots(figsize=(4, 3))  # Aspect ratio of 4:3\n",
        "    for track_id in speed_data.keys():\n",
        "        ax.plot(range(frame_count), speed_data[track_id], label=f\"Speed {track_id}\")\n",
        "    for track_id in distance_data.keys():\n",
        "        ax.plot(range(frame_count), distance_data[track_id], label=f\"Distance {track_id}\")\n",
        "    ax.legend()\n",
        "    ax.set_title(\"Speed and Distance Identification of Each Class\")\n",
        "    ax.set_xlabel(\"Frame Count\")\n",
        "    ax.set_ylabel(\"Value\")\n",
        "    plt.close(fig)\n",
        "    return fig\n",
        "\n",
        "def create_scatter_plot(data):\n",
        "    fig, ax = plt.subplots(figsize=(4, 3))  # Aspect ratio of 4:3\n",
        "    x = list(data.keys())\n",
        "    y = list(data.values())\n",
        "    ax.scatter(x, y)\n",
        "    ax.set_title(\"Class Distribution Scatter Plot\")\n",
        "    ax.set_xlabel(\"Class\")\n",
        "    ax.set_ylabel(\"Count\")\n",
        "    plt.close(fig)\n",
        "    return fig\n",
        "\n",
        "def fig_to_img(fig):\n",
        "    fig.canvas.draw()\n",
        "    img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "    img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "    return img\n",
        "\n",
        "def resize_and_place_image(base_image, overlay_image, position):\n",
        "    overlay_image_resized = cv2.resize(overlay_image, (w // 3, h // 3))\n",
        "    x, y = position\n",
        "    base_image[y:y + overlay_image_resized.shape[0], x:x + overlay_image_resized.shape[1]] = overlay_image_resized\n",
        "    return base_image\n",
        "\n",
        "def draw_visualizations(frame, data, labels, speed_data, distance_data, frame_count):\n",
        "    vis_frame = np.zeros((h, w // 3, 3), dtype=np.uint8)\n",
        "\n",
        "    # Create Pie Chart\n",
        "    if data:\n",
        "        pie_chart = create_pie_chart(data)\n",
        "        pie_chart_img = fig_to_img(pie_chart)\n",
        "        vis_frame = resize_and_place_image(vis_frame, pie_chart_img, (0, 0))\n",
        "\n",
        "    # Create Bar Plot\n",
        "    if data:\n",
        "        bar_plot = create_bar_plot(data)\n",
        "        bar_plot_img = fig_to_img(bar_plot)\n",
        "        vis_frame = resize_and_place_image(vis_frame, bar_plot_img, (0, h // 3))\n",
        "\n",
        "    # Create Multiple Line Plot\n",
        "    if speed_data or distance_data:\n",
        "        line_plot = create_multiple_line_plot(speed_data, distance_data, frame_count)\n",
        "        line_plot_img = fig_to_img(line_plot)\n",
        "        vis_frame = resize_and_place_image(vis_frame, line_plot_img, (0, 2 * (h // 3)))\n",
        "\n",
        "    combined_frame = np.hstack((frame, vis_frame))\n",
        "    return combined_frame\n",
        "\n",
        "def pad_lists_to_length(data_dict, length, default_value=0):\n",
        "    for key in data_dict.keys():\n",
        "        if len(data_dict[key]) < length:\n",
        "            data_dict[key] += [default_value] * (length - len(data_dict[key]))\n",
        "\n",
        "# Define the desired classes and their corresponding IDs\n",
        "#desired_classes = {'person': 0, 'car': 2, 'horse': 17}\n",
        "desired_classes = {'horse':17, 'person': 0,'car': 2, 'van': 8,'bus': 5,'tree': 62}\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, frame = cap.read()\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # Object detection for speed estimation\n",
        "    speed_tracks = speed_estimation_model.track(frame, persist=True, show=False)\n",
        "    frame = speed_obj.estimate_speed(frame, speed_tracks)\n",
        "\n",
        "    # Object detection for distance estimation\n",
        "    annotator = Annotator(frame, line_width=2)\n",
        "    results = object_detection_model.track(frame, persist=True)\n",
        "\n",
        "    if results[0].boxes.id is not None:\n",
        "        boxes = results[0].boxes.xyxy.cpu()\n",
        "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "        clss = results[0].boxes.cls.cpu().tolist()\n",
        "\n",
        "        for box, track_id, cls in zip(boxes, track_ids, clss):\n",
        "            cls_name = object_detection_model.names[int(cls)]\n",
        "            if cls_name in desired_classes and desired_classes[cls_name] == cls:  # Filter desired classes and IDs\n",
        "                if cls_name not in labels:\n",
        "                    labels.append(cls_name)\n",
        "\n",
        "                if cls_name in data:\n",
        "                    data[cls_name] += 1\n",
        "                else:\n",
        "                    data[cls_name] = 1\n",
        "\n",
        "                annotator.box_label(box, label=str(track_id), color=bbox_clr)\n",
        "                annotator.visioneye(box, center_point)\n",
        "\n",
        "                x1, y1 = int((box[0] + box[2]) // 2), int((box[1] + box[3]) // 2)  # Bounding box centroid\n",
        "\n",
        "                distance = (math.sqrt((x1 - center_point[0]) ** 2 + (y1 - center_point[1]) ** 2)) / pixel_per_meter\n",
        "\n",
        "                text_size, _ = cv2.getTextSize(f\"Distance: {distance:.2f} m\", cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)\n",
        "                cv2.rectangle(frame, (x1, y1 - text_size[1] - 10), (x1 + text_size[0] + 10, y1), txt_background, -1)\n",
        "                cv2.putText(frame, f\"Distance: {distance:.2f} m\", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 1.2, txt_color, 3)\n",
        "\n",
        "                if track_id not in distance_over_time:\n",
        "                    distance_over_time[track_id] = [0] * (frame_count - 1)\n",
        "                distance_over_time[track_id].append(distance)\n",
        "\n",
        "                speed = speed_obj.speeds.get(track_id, 0) if hasattr(speed_obj, 'speeds') else 0\n",
        "                if track_id not in speed_over_time:\n",
        "                    speed_over_time[track_id] = [0] * (frame_count - 1)\n",
        "                speed_over_time[track_id].append(speed)\n",
        "\n",
        "    # Pad lists to current frame count to ensure equal lengths\n",
        "    pad_lists_to_length(distance_over_time, frame_count)\n",
        "    pad_lists_to_length(speed_over_time, frame_count)\n",
        "\n",
        "    # Draw combined visualizations on the frame\n",
        "    combined_frame = draw_visualizations(frame, data, labels, speed_over_time, distance_over_time, frame_count)\n",
        "\n",
        "    # Write the frame with visualizations\n",
        "    out.write(combined_frame)\n",
        "\n",
        "    # Clear counts for next frame\n",
        "    data = {}\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "# Generate and overlay scatter plot on the final frame\n",
        "final_frame = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "scatter_plot = create_scatter_plot(class_counts_over_time)\n",
        "scatter_plot_img = fig_to_img(scatter_plot)\n",
        "final_frame = resize_and_place_image(final_frame, scatter_plot_img, (0, 0))\n",
        "\n",
        "\n",
        "# Save the final frame with the scatter plot\n",
        "cv2.imwrite(\"final_frame_with_scatter_plot.png\", final_frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}